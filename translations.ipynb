{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translations.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install youtokentome\n",
        "!pip install pytelegrambotapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iddHF7PiKDM-",
        "outputId": "816452ce-d953-45ea-e000-3aa679373884"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtokentome\n",
            "  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n",
            "Collecting pytelegrambotapi\n",
            "  Downloading pyTelegramBotAPI-4.4.0.tar.gz (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytelegrambotapi) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytelegrambotapi) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytelegrambotapi) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytelegrambotapi) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytelegrambotapi) (3.0.4)\n",
            "Building wheels for collected packages: pytelegrambotapi\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-4.4.0-py3-none-any.whl size=128152 sha256=4aef33818b739f0a54153bb6ff59aa53253dcf517a9f920163d1f210cfced4ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/6d/ff/435b12799b8212017f08dbbfdb7a1e5174d72d20fb7c0f4703\n",
            "Successfully built pytelegrambotapi\n",
            "Installing collected packages: pytelegrambotapi\n",
            "Successfully installed pytelegrambotapi-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1ziBcswF_zllclO2laZP7KrqFsn-eorGR\n",
        "!gdown --id 1tUnOlmPWWU1ri31l2QlQM59Hs4xhtJt8\n",
        "!gdown --id 1hEgmZQetO0W373-MdsRrrq6kYNSfDmhr\n",
        "!gdown --id 1ehMlyygXlJXWelTmkzUaGWWmVh1Q1bB9\n",
        "!gdown --id 1OKCeRoefDIEN-PgRyVsBjSJkl97lXU5_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtkTl_D9O2as",
        "outputId": "40930b6f-91e2-4b6e-d8b0-f17033ddbaee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ziBcswF_zllclO2laZP7KrqFsn-eorGR\n",
            "To: /content/last-val-model.pt\n",
            "100% 58.6M/58.6M [00:00<00:00, 81.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tUnOlmPWWU1ri31l2QlQM59Hs4xhtJt8\n",
            "To: /content/best-val-model.pt\n",
            "100% 58.6M/58.6M [00:00<00:00, 75.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hEgmZQetO0W373-MdsRrrq6kYNSfDmhr\n",
            "To: /content/trg_vocab.pth\n",
            "100% 489k/489k [00:00<00:00, 34.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ehMlyygXlJXWelTmkzUaGWWmVh1Q1bB9\n",
            "To: /content/src_vocab.pth\n",
            "100% 442k/442k [00:00<00:00, 99.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OKCeRoefDIEN-PgRyVsBjSJkl97lXU5_\n",
            "To: /content/bpe_en.bin\n",
            "100% 203k/203k [00:00<00:00, 67.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IczlH6j_JxA5"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import telebot\n",
        "from youtokentome import BPE\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "src_vocab = torch.load('src_vocab.pth')\n",
        "trg_vocab = torch.load('trg_vocab.pth')\n",
        "bpe_en = BPE('bpe_en.bin')\n",
        "\n",
        "SRC_PAD = src_vocab.stoi['<pad>']\n",
        "TRG_PAD = trg_vocab.stoi['<pad>']\n",
        "INP_DIM = len(src_vocab)\n",
        "OUT_DIM = len(trg_vocab)\n",
        "HID_DIM = 256\n",
        "N_LAYERS = 3\n",
        "N_HEADS = 8\n",
        "DROPOUT = 0.1\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, hid_dim, n_heads, dropout):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = nn.MultiheadAttention(hid_dim, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.attn_norm = nn.LayerNorm(hid_dim)\n",
        "        self.fc1 = nn.Linear(hid_dim, 2 * hid_dim)\n",
        "        self.fc2 = nn.Linear(2 * hid_dim, hid_dim)\n",
        "        self.ff_norm = nn.LayerNorm(hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, src, src_pad_mask, src_attn_mask):\n",
        "\n",
        "        x, _ = self.attn(src, src, src, key_padding_mask=src_pad_mask, attn_mask=src_attn_mask)\n",
        "        src = self.attn_norm(src + self.dropout(x))\n",
        "        fc1 = torch.relu(self.fc1(src))\n",
        "        fc2 = self.fc2(self.dropout(fc1))\n",
        "        src = self.ff_norm(src + self.dropout(fc2))\n",
        "        return src\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim, hid_dim, n_heads, n_layers, batch_size, max_len, dropout):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = nn.Embedding(in_dim, hid_dim)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        freq = torch.exp(-torch.arange(hid_dim // 2) * 2 / hid_dim * torch.log(torch.FloatTensor([10000])))\n",
        "        pos_enc = torch.zeros(max_len, 1, hid_dim)\n",
        "        pos_enc[:, 0, 0::2] = torch.sin(position * freq)\n",
        "        pos_enc[:, 0, 1::2] = torch.cos(position * freq)\n",
        "        self.pos_enc = pos_enc.repeat(1, batch_size, 1).permute(1, 0, 2).contiguous().to(device)\n",
        "\n",
        "        self.encoder = nn.ModuleList([EncoderBlock(hid_dim, n_heads, dropout) for i in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, src, src_pad_mask, src_attn_mask):\n",
        "\n",
        "      src = self.dropout(self.emb(src) * self.scale + self.pos_enc[:src.size(0),:src.size(1),:])\n",
        "\n",
        "      for block in self.encoder:\n",
        "          src = block(src, src_pad_mask, src_attn_mask)\n",
        "\n",
        "      return src\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, hid_dim, n_heads, dropout):\n",
        "\n",
        "        super().__init__()\n",
        "    \n",
        "        self.dec_attn = nn.MultiheadAttention(hid_dim, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.dec_attn_norm = nn.LayerNorm(hid_dim)\n",
        "        self.cross_attn = nn.MultiheadAttention(hid_dim, n_heads, dropout=dropout, batch_first=True)\n",
        "        self.cross_attn_norm = nn.LayerNorm(hid_dim)\n",
        "        self.fc1 = nn.Linear(hid_dim, 2 * hid_dim)\n",
        "        self.fc2 = nn.Linear(2 * hid_dim, hid_dim)\n",
        "        self.ff_norm = nn.LayerNorm(hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, trg, trg_pad_mask, trg_attn_mask, src, cross_pad_mask, cross_attn_mask):\n",
        "        \n",
        "        x, _ = self.dec_attn(trg, trg, trg, key_padding_mask=trg_pad_mask, attn_mask=trg_attn_mask)\n",
        "        trg = self.dec_attn_norm(self.dropout(x) + trg)\n",
        "        x, attn = self.cross_attn(trg, src, src, key_padding_mask=cross_pad_mask, attn_mask=cross_attn_mask)\n",
        "        trg = self.cross_attn_norm(self.dropout(x) + trg)\n",
        "        fc1 = torch.relu(self.fc1(trg))\n",
        "        fc2 = self.fc2(self.dropout(fc1))\n",
        "        trg = self.ff_norm(trg + self.dropout(fc2))\n",
        "        return trg, attn\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, out_dim, hid_dim, n_heads, n_layers, batch_size, max_len, dropout):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = nn.Embedding(out_dim, hid_dim)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        freq = torch.exp(-torch.arange(hid_dim // 2) * 2 / hid_dim * torch.log(torch.FloatTensor([10000])))\n",
        "        pos_enc = torch.zeros(max_len, 1, hid_dim)\n",
        "        pos_enc[:, 0, 0::2] = torch.sin(position * freq)\n",
        "        pos_enc[:, 0, 1::2] = torch.cos(position * freq)\n",
        "        self.pos_enc = pos_enc.repeat(1, batch_size, 1).permute(1, 0, 2).contiguous().to(device)\n",
        "\n",
        "        self.decoder = nn.ModuleList([DecoderBlock(hid_dim, n_heads, dropout) for i in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "        self.out = nn.Linear(hid_dim, out_dim)\n",
        "\n",
        "\n",
        "    def forward(self, trg, trg_pad_mask, trg_attn_mask, src, cross_pad_mask, cross_attn_mask):\n",
        "\n",
        "        trg = self.dropout(self.emb(trg) * self.scale + self.pos_enc[:trg.size(0),:trg.size(1),:])\n",
        "\n",
        "        for block in self.decoder:\n",
        "            trg, attn = block(trg, trg_pad_mask, trg_attn_mask, src, cross_pad_mask, cross_attn_mask)\n",
        "\n",
        "        return self.out(trg), attn\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim, out_dim, hid_dim, n_heads, n_layers, dropout, batch_size, src_pad, trg_pad, max_len=1000):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.src_pad = src_pad\n",
        "        self.trg_pad = trg_pad\n",
        "        self.encoder = Encoder(in_dim, hid_dim, n_heads, n_layers, batch_size, max_len, dropout)\n",
        "        self.decoder = Decoder(out_dim, hid_dim, n_heads, n_layers, batch_size, max_len, dropout)\n",
        "        \n",
        "    \n",
        "    def make_pad_mask(self, x, pad_id):\n",
        "\n",
        "        return (x == pad_id)\n",
        "\n",
        "\n",
        "    def make_attn_mask(self, x_size, y_size, mode):\n",
        "\n",
        "        if mode == 'src':\n",
        "            return torch.ones(x_size, y_size)\n",
        "        else:\n",
        "            mask = torch.triu(torch.ones(x_size, y_size), diagonal=1)\n",
        "            mask[mask.bool()] = -float('inf')\n",
        "            return mask\n",
        "\n",
        "    \n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        s = src.size(1)\n",
        "        t = trg.size(1)\n",
        "        src_pad_mask = self.make_pad_mask(src, self.src_pad).to(device)\n",
        "        cross_pad_mask = self.make_pad_mask(src, self.src_pad).to(device)\n",
        "        trg_pad_mask = self.make_pad_mask(trg, self.trg_pad).to(device)\n",
        "        src_attn_mask = self.make_attn_mask(s, s, 'src').to(device)\n",
        "        cross_attn_mask = self.make_attn_mask(t, s, 'cross').to(device)\n",
        "        trg_attn_mask = self.make_attn_mask(t, t, 'trg').to(device)\n",
        "\n",
        "        enc_src = self.encoder(src, src_pad_mask, src_attn_mask)\n",
        "        output, attention = self.decoder(trg, trg_pad_mask, trg_attn_mask, enc_src, cross_pad_mask, cross_attn_mask)\n",
        "        return output, attention\n",
        "\n",
        "\n",
        "model = Transformer(INP_DIM,\n",
        "                    OUT_DIM,\n",
        "                    HID_DIM,\n",
        "                    N_HEADS,\n",
        "                    N_LAYERS,\n",
        "                    DROPOUT,\n",
        "                    BATCH_SIZE,\n",
        "                    SRC_PAD,\n",
        "                    TRG_PAD).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load('last-val-model.pt'))\n",
        "\n",
        "\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        tokens = [bpe_en.id_to_subword(token) for token in bpe_en.encode(sentence.lower())]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = ['<sos>'] + tokens + ['<eos>']\n",
        "        \n",
        "    src_indexes = [src_field.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_pad_mask = model.make_pad_mask(src_tensor, model.src_pad).to(device)\n",
        "\n",
        "    src_attn_mask = model.make_attn_mask(src_tensor.size(1), src_tensor.size(1), 'src').to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_pad_mask, src_attn_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.stoi['<sos>']]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_pad_mask = model.make_pad_mask(trg_tensor, model.trg_pad).to(device)\n",
        "\n",
        "        trg_attn_mask = model.make_attn_mask(trg_tensor.size(1), trg_tensor.size(1), 'trg').to(device)\n",
        "\n",
        "        cross_pad_mask = model.make_pad_mask(src_tensor, model.src_pad).to(device)\n",
        "\n",
        "        cross_attn_mask = model.make_attn_mask(trg_tensor.size(1), src_tensor.size(1), 'cross').to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, trg_pad_mask, trg_attn_mask, enc_src, cross_pad_mask, cross_attn_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.stoi['<eos>']:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.itos[i] for i in trg_indexes][1:-1]\n",
        "\n",
        "    result = ''.join(trg_tokens)\n",
        "    \n",
        "    return result.replace('▁', ' '), attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation, attention = translate_sentence(input(), src_vocab, trg_vocab, model, device)\n",
        "\n",
        "print(f'TRANSLATION = {translation}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWIOeGW3NB3U",
        "outputId": "05a1fae0-67b7-4b9a-c883-0bcd3f7e887d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have a dog\n",
            "TRANSLATION =  sɛiɣ aydi-ines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = '5252552654:AAFUbQXT3vgB4ipTqQFPeQTgpRFrWoinQuo'\n",
        "bot = telebot.TeleBot(token)\n",
        "\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start_message(message):\n",
        "    bot.send_message(message.chat.id, 'Введите текст на английском языке для перевода.')\n",
        "\n",
        "@bot.message_handler(commands=['bleu'])\n",
        "def report_bleu(message):\n",
        "    bot.send_message(message.chat.id, 'BLEU = 22.34')\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def translate(message):\n",
        "    translation, attention = translate_sentence(message.text, src_vocab, trg_vocab, model, device)        \n",
        "    bot.send_message(message.chat.id, ' '.join(translation))\n",
        "\n",
        "bot.polling(none_stop=True)"
      ],
      "metadata": {
        "id": "IHdF-J2SNZpQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vBkaQF1Lri-6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}